{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOW TO CONDUCT A NEAR TO PERFECT MACHINE LEARNING PROJECT:\n",
    "    1. Examine your problem \n",
    "        its good to know what type of data you are working with(Numerical, Categorical, or images).\n",
    "        what is the end goal of your model?\n",
    "        How will I define and measure 'accuracy'?\n",
    "        Do I have an idea of what algorithm will work best on this type of project and data?\n",
    "\n",
    "    2. prepare your data(raw data, feature extraction, feature engineering)\n",
    "        Here you load the data from your disk, examine it, and decide whether you need to perfom feature extraction or \n",
    "        feature engineering.\n",
    "            #Feature extraction involves applying an algorithm to quantify your data\n",
    "            #feature engineering involves transforming your raw input data into a representation that better represent the \n",
    "            underlying the problem. \n",
    "\n",
    "    3. Spot check different algorithms\n",
    "        Here you simply take a set of various ML Algorithms and apply them to the dataset with a goal of gaining an \n",
    "        experience to your project and understanding which ML Algorithm performs well on the problem and which one do not \n",
    "        do well. \n",
    "        \n",
    "    4. Examine the results\n",
    "        Here you are able to understand which machine learning model worked well and which did not work well. \n",
    "        You are able also to see patterns that emerge across multiple experiments you have done. \n",
    "        You discover which and in when does a specific algorithm peform well. \n",
    "\n",
    "    5. Double down on the algorithms that worked best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the different algorithms you can use:\n",
    "    1. K-Nearest Neighbors(K-NN)\n",
    "    2. Naive Bayes\n",
    "    3. Logistic Regression\n",
    "    4. Support Vector Machines(SVMs)\n",
    "    5. Decision Trees\n",
    "    6. Random Forest\n",
    "    7. Convolutional Neural Network (CNN)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating the first neural network using MNIST FASHION DATASET\n",
    "#MNIST(Modified National Institute of Standards and Technology)\n",
    "\n",
    "#the dataset contain images of 10 different types of clothes from shirts, trousers, dresses etc.\n",
    "#every image grid has a size of 28 * 28 with pixel value between 0 and 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tensorflow package\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Loading Mnist dataset from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images,training_labels), (test_images, test_labels) = data.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the downloaded data has 60,000 training images and 10,000 test images and thus running data.load_data code gives an array of 60,000 28*28 pixel arrays(training images) & 60,000 values (0-9) training labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the test images and test labesl is held back so as the model doe not see them during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZING\n",
    "the model is normalized to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the pixels in the images in data are grayscale with values between 0 - 255.test_images.test_images\n",
    "# dividing by 255 ensures every pixel gets represented by a single number either 1 or 0.\n",
    "#  this process is called normalizing\n",
    "training_images = training_images / 255.0\n",
    "\n",
    "test_images = test_images /255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten- the input layer with inputs of 28*28 images. It turns the gray boxes which have a square value (2D) and convert it into 1D.\n",
    "Dense- a layer of neurons(hidden layer). selects 128 neurons randomly in order to have their internal parameters randomly initialized. \n",
    "#You can not select more Neurons as the model will run slowly, and overfitting(the neural network recognizes training data better than it recognizes new data)\n",
    "#fewer neurons also means the network will not have enough parameters to learn.\n",
    "You select the right values through a process called #Hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the activation function is a code that will execute on each neuron in the layer. the one used is relu(Rectified Linear Unit). it returns a value if its greater than 0. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Dense layer- this is the output layer and has 10 neurons since we have 10 different classes. each neuron ends up with a probability of each input matching to the classes, so we use softmax activation function to match with th one with the highest probability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter- value that is used to control training of a network\n",
    "parameter- internal values of neurons that get trained/learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128,activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10,activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compiling the model by specifying the loss function.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse categorical cross entropy is a Categorical loss function built into tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])#reporting back accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.5016 - accuracy: 0.8236\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3785 - accuracy: 0.8632\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3401 - accuracy: 0.8767\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3152 - accuracy: 0.8842\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2967 - accuracy: 0.8905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d79f84fa0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)#here the code trains the model epoch by epoch\n",
    "#it reports the accuracy and loss, when the loss decreases, the accuracy increases as the number of epochs increases. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Evaluating the model on the test data. \n",
    "#here we get to see the accuracy of the model.\n",
    "#the accuracy reported might be lower than the accuracy in the training data. \n",
    "this is because the neural network only knows how to much inputs it has been trained on with output of those values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3551686406135559, 0.8715000152587891]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Exploring the Model Output\n",
    "the classification gives back an array of values of the 10 output neurons.\n",
    "the values are probabilities that an image matches the label at a given index.  \n",
    "the results are after using 5 epochs and looking at a test image index 1. the neural network reports that there's a 99.9% chance the  item of clothing at index 0 is labeled 9. \n",
    "\n",
    "when you try a different index like 9, the accuracy gets to 68.9% chance of recognizing label 7."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you train for longer (increase the number of epochs), the accuracy increases in both test set and training set. \n",
    "#Training for long does not always result to a good model, it can cause overfitting. Its better to know what accuracy you want your model to attain with that, you are able to play around with the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[5.2384093e-09 5.4846145e-09 2.0803914e-09 2.4999158e-08 2.4036526e-10\n",
      " 3.2031487e-04 1.6671866e-09 9.9931872e-01 1.1795587e-06 3.5976828e-04]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[9])\n",
    "print(test_labels[9])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to attain a certain accuracy without knowing how many epochs will help you attain the accuracy, you can use a #CALLBACK during training\n",
    "\n",
    "lets see what will happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: here we have used 60 epochs and we are adding the callback parameter and then passing the callbacks object. in the class we define the on_epoch_end function that gives the details for the logs of the epoch. \n",
    "The callback function is called during training and at epoch 34, the training stops since the model has attained the target of 95% accuracy.\n",
    "If the accuracy gets higher than 95% as we have specified, the model stops training (self.model.stop_training = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.9520\n",
      "Reached 95% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1269 - accuracy: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d798f7220>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images,training_labels,epochs=50,\n",
    "callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bae786896c56b90ec54b6c27391114c56d1d520de77ac1c092debf939420080e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
